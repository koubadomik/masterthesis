\chapter{Introduction} \label{chap:intro}
\section*{Motivation}
In this day and age, we face an intense explosion of machine learning applications in various branches of human efforts such as biology, chemistry, physics, and others. These technologies widely influence our daily lives and make them immensely more convenient, faster, and more enjoyable. On the other hand, there are many cases where algorithms (especially in machine learning) can control our decisions, reasoning, and life.

If we use these computer science tools appropriately, we can often create something that may serve our protection. We can take the detection of threats and frauds in cybersecurity as a perfect example, research and applications in this particular field are fascinating for multiple reasons, and one of them is our motivation. We have to know which side we are standing on and what the interests of our clients are. In the case of fraud detection, we know that the investment is profitable only if the fraud has a significant financial impact. Not all frauds are interesting from a financial point of view because solving them also costs much money. However, from an ethical point of view, every fraud should be punished. Similarly, network security, single device security, and access control are often disregarded. Small businesses targeting a specific market are not interested in costly services whose impact is mainly preventive. The primary objective of such business is cost reduction and financial profit. Nevertheless, it cannot be denied that loss of privacy and data is undesirable. We have to start analyzing costs, benefits, risks, probability, and impact (potential damage). That is not so evident in a technical branch as cybersecurity is.

An inseparable character of this play is malware. Let us motivate this thesis by listing several examples.

Firstly, one of the most prevalent malicious software is \emph{ransomware}. Its overall damage is estimated to be $\$20$ billion, increasing every year \cite{purplesec2021}. Though the social impact might be arguably even more significant than the financial side as there have been attacks targetting even healthcare organizations, which is further exacerbated by the fact that the first death following a ransomware attack was reported in 2020 \cite{Cimpanu2020}.

We can conclude that IoT malware is becoming more common, supported by Sonic Wall's 2019 report. That is caused by the insufficient protection of these small devices, for which we cannot provide complete malware protection. However, 127 new IoT devices are being connected to the internet every second, which leads us to an estimation that by the end of 2021, there will be 35 billion IoT devices connected to the internet \cite{TheIoTRu52:online}. This risk can not be mitigated easily, and malware elimination will play an even more significant role as it has so far.

Another convenient trend for malware is widespread encryption, which has become a standard in web traffic. Its main goal is the security of information. Considering this fact, the creators of malware have a lot to hide and secure from the protectors as well. The encryption might inform us that the source has something that nobody else should see. A long-lasting trend of such behaviour might be suspicious. We can check if there is a justified reason to encrypt the data, or we can at least make some conclusions about the source of the encrypted data. Nevertheless, that is not possible in the world where everything is encrypted.

In 2020, 94\% of malware was delivered by email \cite{Topcyber13:online}, and therefore the importance of phishing emails with malicious attachments and other social engineering techniques grows. It is cheaper to produce one sophisticated, convincing email to retrieve some information than an attempt to attack a highly protected network perimeter. It also might be used to distribute malware or other threats.

In 2020 AV-atlas \cite{AVATLASM39:online} recorded over 750 million malware samples, and moreover, at the end of April 2021, this number has increased to over 820 million malware samples. The majority of them are executable files attacking Windows devices.

Malware research continues, and it will undoubtedly do so until we can introduce a sufficiently universal and flexible solution that will be able to detect zero-day threats (unseen). We might find a solution among machine learning models, which are often involved. However, its challenge is interpretability and explainability, not only in cybersecurity. We face the problem that a model's performance is often significant, but we are not sure about the reason, and it is risky to deploy such a model to a situation where it can meet unseen data. High-quality security engineers do not have to be high-quality machine learning engineers. If we want to involve machine learning methods increasingly, we need to interpret and explain its predictions to combine cybersecurity knowledge with the results of the models and gain a better understanding. 


\section*{Goal}
The main objective of this thesis is to design a pipeline that has a malware file dataset as the input and a machine learning model and its explanation as the output. We want to go through the whole process, document each step, and report results. Our acquisition is the process itself, so it is described in detail for the reader to identify the problems we experienced and replicate or extend our setup.

From the assignment of this thesis, we can extract the following steps:
\begin{enumerate}
    \itemsep0em 
    \item Run several instances of \emph{CAPEv2} \cite{Cape} sandbox and solve their orchestration for this experiment
    \item Capture the behaviour of selected malware samples and store the results
    \item Learn the hierarchical multiple instance learning (\emph{HMill}) framework
    \item Analyze the captured data. Report the basic statistics and choose appropriate features and hidden states for further modelling
    \item Using HMill, create models and identify the artefacts corresponding to different malware behaviour, and report the results
    \item Investigate which parts of the \emph{CAPEv2} log are important to different malware behaviour
\end{enumerate}
\subsection*{In detail}
The first step implies using dynamic malware analysis to retrieve the input for our machine learning model. This intention originated after we downloaded a couple of thousands of sandbox \emph{JSON} reports from the internet and examined them. We observed that this use case might be challenging for our method and might demonstrate its capabilities.

The initial task is data collection. We are about to use MalwareBazaar\footnote{https://bazaar.abuse.ch/} as a public data source of malware samples. We chose it because of its free access with no claims for usage and a reasonable amount of samples. We aim at \emph{Portable Executable} (PE), which does not require any additional software running on the target machine. The sandbox we want to use is \emph{CAPEv2} \cite{Cape} because the first reports were also produced by this tool, and they are sufficient for analysis purposes.  It is a fork of a popular \emph{Cuckoo} sandbox which is no longer maintained. The sandbox has to be run in multiple instances to collect a sufficient number of samples.

The model we want to use is a \emph{hierarchical multiple instance learning} model. In \cite{Mandlik2020}, the authors showed that this model has good performance modelling \emph{JSON} documents. After further research, we decided to model the dependence of malware \emph{signatures} on behavioural features, both included in \emph{JSON} report. Signatures are the essential input for the original classification techniques used by the sandbox, and we want to see how well the model predicts them based on malware behaviour.

Finally, we will attempt to explain the predictions by choosing a minimal subset of features that contributes to the model's prediction the most. The explanation will be performed using the existing \emph{HMill} explainer. We can study the implementation of signatures and their true cause, which might help us with results evaluation. We expect that explanation of the model, the cause of which is in the report, should be a set containing this cause. As an example, we expect that if the original signature's cause is a specific API call, it should be presented in the explanation of the binary classifier for this signature. As authors of \emph{HMill} explainer mentioned, we hope that the explanation contains even something new. In other words, we expect that we could observe explanations that contain entries that are not the original cause. However, they might reasonably substitute it --- they are connected to the same effects. It is also possible to identify new signatures because all samples are malicious and the model might generalize based on different similarities in the training set.

\section*{Thesis structure}
The thesis is divided into two main parts. In the first part, we focus on the theoretical background of our method. In the second part, we present a specific setup, our results, and their discussion. More complex structures (images, tables) are part of the appendices. The attachments containing additional material are described in \ref{app:attach}.

The theoretical part starts with the malware analysis theory in chapter \ref{chap:analysis} where we break down the malware itself, the types of its analyses, and its output. We continue in the chapter \ref{chap:classification} which describes the machine learning formalism, cybersecurity context, and structured data (\emph{JSON} document) usage in machine learning. Finally, the chapters \ref{chap:hmill} and \ref{chap:expth} describe the particular methods used in our modelling and explaining experiments.

The second part consists of two chapters. Chapter \ref{chap:infrastructure} includes a description of the infrastructure and the data collection process. Chapter \ref{chap:results} presents the model and explainer setup, results, and their discussion.