\chapter{Infrastucture and data collection} \label{chap:infrastructure}
This chapter desribes realization of data collection process using \emph{CAPEv2} sandbox, problems we experienced and their solution. Theoretical background is in \ref{chap:analysis}. At the beginning we have data source of malware samples mentioned in the thesis introduction \url{https://bazaar.abuse.ch/}. The output of this task is dataset of dynamic malware analyses. It includes behavioral features and signatures, both input for our \emph{hmill} model.

Although this chapter is not so long as previous ones because not all troubles are expressible in written text we spent with this task the largest amount of time. All scripts and other outcomes are part of the attachment (\ref{app:attach}) and the most important tools are listed in \ref{app:stack}.

\section{Host machine}
The host machine is where the sandbox environment and a virtualization software is running. We knew that analysis of one malware sample take up to five minutes and we would like to have as many samples as possible. That is why we wanted to create distributed run of several host machines. The whole process of host machine initialization is automated by bash script to be able to setup multiple machines. Usefull side effect of this is that the whole process might be reproduced.

The initilization consists of several steps:
\begin{itemize}
    \item Install host operating system - recommended Ubuntu
    \item Enable SSH to be able to access remotely
    \item Enable basic security - firewall and supporting tools
    \item Install virtualization software - recommended KVM Qemu
    \item Copy virtual machine images to the host machine
    \item Sandbox initialization
    \item Data collection script initilization
\end{itemize}

To be able to run all steps of the script on multiple machines at once we used network orchestration tool Ansible. We also added some usual management functions - copy new configuration from server and clean the sandbox data.

Hardware resources on host machines are 256GB SSD and 16GB RAM sufficient number of virtual machines per one host is four. We experimented with more but there was an overload which might lead to biased analysis results.

Automation of the whole process was accompanied by various issues. These issues were caused mainly by low experience. Sometimes poor documentation was involved. Especially the process of virtual machine images copying was connected with issues of automated snapshot take. Such process needs often manual steps and their automation was very challenging.

\section{Guest - virtual machines}
Guest machine denotes the machine where the malware sample is running and where the cape monitor is operating. We used Windows 7 as operating system under CTU in Prague licence. The crucial goal setting up guest machine is that it should look like normal computer which is used. Due to virtualization usage we have to care about sandbox evasion techniques mentioned in \ref{chap:analysis}.

There are two options for anti-evasion setup along with \emph{CAPEv2} sandbox. Firstly, we experimented with vmcloak\footnote{https://github.com/hatching/vmcloak}. We were able to run and use this tool but it supports only VirtualBox which is not recommended by \emph{CAPEv2} contributors because of its performance. Project is also no longer maintained and some functions did not work (taking snapshots). Second option is to use script recommended by sandbox contributors\footnote{https://github.com/doomedraven/Tools/blob/master/Virtualization/kvm-qemu.sh} and perform manual steps in the virtual machine configuration\footnote{https://www.doomedraven.com/2016/05/kvm.html#modifying-kvm-qemu-kvm-settings-for-malware-analysis}. We were not succesful several times because of misconfigurations in low level virtual machine configuration but finally we were able to create several correct images.

The sandbox require disabling firewall and running python on guest machine beside this we added most seen applications like Google Chrome, Firefox, Adobe reader, Spotify\dots We added one private key to C://Users/Administrator/.ssh and one password to google chrome password database. We added random images and documents from the internet.

\section{Network setup}
problems with their setup
images - physical, logical (images from https://github.com/koubadomik/cuckoo-distr-docs)
describe each part

figure of the setup, description, argumentation
similar projects (isolation of malware network having internet access)
two branches - no internet, internet
internet
    describe in detail
    firewall
    security resoning
    syslog...
safe network made our work easier, mention couple of further ideas mentioned by Josef (thank to Josef at the beginning of thesis!)

\section{Abuse.ch}
Possible sources
Chosen source
- recommendation from team member
- description of Abuse.ch
- possible problems - bias?, Emotet results?, Some statistic from the report from VT which I downloaded (nice-to-have), maybe could be quite interesting to retrive list of file extentions - histogram?


\section{Data collection pipeline}
TODO: create image of pipeline, describe each part

Download samples from abuse
Filter samples by file type (PE) - filtered directly pe files and then extracted zip files and filtered again
Add filtered samples to database (store in json file, which I backup regularly, later could be improved)
Retrieve additional metadata for files (VT)
Distribute samples to slaves (each file should be analysed in each mode, for distribution REST API of cape sandbox is used)
Collect and store results

distibution - describe our problems with distribution part and other motivation to create more complex architecture
First phase of our work is about running chosen sandbox to capture sigificant number of analysis results for further use. This task could be divided into two subtask - building infrastructure and data collection. Due to the fact that we would like to collect more than $50 000$ samples and usual analysis take $5$ minutes we will need more than one active instance so the distribution is another challenge.


\section{Sample filtering}
Principle of detecting PE files - my way (reference file command,...)
Mention even that some files are zipped and we decompressed them and added results between our samples
Mention from some book how we can do this - I saw it in static analysis

\subsection{Static analysis}
VT, Metadefender and abuse reports, mention academic access for VT so we end up with that only

There is some useful info in this data. But nothing totally awesome. But good enough for pre-sorting.
Interesting are:

Abuse.CH:
- First seen: Us the oldest date to estimate how old the sample is. We need that for time scales
- ssdeep: Fuzzy hash, good to find similar samples
- sha256: Most common hash to link them together
- md5/.../other hashes: Sometimes used in articles. Keep them for reference

Metadefender:
Multi-scanner. Be aware to check which Av detected it. Only use the top 10 (check out av-comparatives or av-test)
Creation date is important. If the sample is older the AVs had some time to add detection (older: Time between first seen and detection)


Virustotal:
Similar to metadefender. Plus: It has update time of engine.
The other data in here:
- Packers: Malware can be packed. A nice hint, if available
- Import list: Used DLL functions. Some malware is loading external functionality during runtime....
- Resources: Attached malware parts (encrypted => high entropy). Maybe also abusing Icons of well known tools (=> trojans)
- Signature: Could be helpful to weed cleanstuff our. If it is properly signed by a authority we can trust....
If we want to classify malware as the first AV vendor seeing it, we can not use the detections others have on it. Obviously.
HTH
Thorsten


\subsection{Sample distribution}
Reference scripts and crons..., sample storage
problems using provided distribution (concretize some, extract from notes, poor docs,..)
using nas storage and so on...



\section{Problems}
sandbox not running, firewall,distributed version

\section{Results of analysis}
Complete description of the output of the sandbox is in appendix \todo{reference}.
Description what everything we have at the end for every single sample, size of dataset (GB and number of samples)...
Try to compare to another public dataset with the attributes and mention that using this way is quite universal
What we have X what the docs says (caused our misconfiguration...) - https://cuckoo.readthedocs.io/en/latest/usage/results/ (reference cuckoo book)

\chapter{Data structure, features and states} \label{chap:data}
The outputs of the previous chapter are dynamic malware analysed samples. Even such experiments used machine learning algorithms on all the produced data, but this is very performance demanding because the output may have 15~\emph{MB} but even gigabytes. That is why we want to choose the only subset containing the most information about the run and behaviour. 

The goal of this thesis is to use \emph{hmill} model (comprehensively described in \ref{chap:hmill}), which can work with graph-structured data and especially with JSON files. This fact we would like to use.

Our approach is to create a simple binary classifier and then scale up to multiclass or even multilabel if possible regarding performance and time. This chapter describes our reasoning on choosing features and hidden states for our \emph{hmill} classifier.  Collected results are input, and the expected output is a set of features and states (maybe more than one possibility). This decision should be based on the data we have and the experience observed in prior work.


\section{Dataset}
We have some of the results which were mentioned in \ref{chap:infrastructure}. When we start the following reasoning, we have the proper amount of the data without internet access because the setup is straightforward and more accessible. The setup with the internet connection and its collected data will be investigated in future work as its collection continues. 

The data in such domain are very biased (\ref{chap:class}). Sometimes we can see that malware can not be run under the conditions in a virtual machine or is trying to use some \emph{.NET} library and if not found, it kills itself. The fact that we do not have an internet connection can make this bias stronger, so we have to count on it to decide what to use to train the model. We do not want to investigate network activities even if sometimes it contains something (malware attempts).

The dataset consists of $80000$ different samples. Complete data have approximately $2,5$~\emph{TB} where the analysis result is compressed.

Not all the outputs described in \ref{chap:analysis} are presented in each sample.



add literally every detail including some scripts to appendix, even configuration of network, vpn, reference manuals, security reasoning during setting up internet connection (see notes)...





Previous connection
- Follow up analysis chapter and summarize what we did
Next connection
- At the end should be described output of sandbox and at the beggining of next chapter should be stated what we have chosen and why





% - Realization of chapter 'data'
% - our infrastructure - distribution, other types of analyses, network infrastructure (marginally, I am not going to use those data, I think, but I performed it and I can write about the risks and so on...)
% - used tools
% - distrbution
% - pipeline
% - run
% - results
% - Conclusions, comming-outs, summary, discussion


% \todo{absorb chapter about data here, describe the output and marginally discussion on what should be feature vector and classes (but present it as ready decision - from the introduction)}

% \todo{this chapter could be absorbed into next chapter if it is too short...}
% \todo{do not forget to add goals to each chapter and go through the trash below each chapter!!}


% Lastly thrown out
% We would like to base our decision on the fact that in \ref{chap:analysis} we stated that crucial observations during the program run are \emph{processes, files, mutexes, registries, commands, api calls}.

% \todo{avoid background things, that should be moved to analysis part, here strictly what we solved and architecture and so on}

% NICE to have
% We can try to create some histogram using the data from virus total (families or something like that...)
% \todo{checkout some web interface example, if there is something else, and even configuration files}
% \todo{add sections of report from virus total and its features}
% https://developers.virustotal.com/v3.0/reference#files
% \todo{add some image}

%%----------------------------------------------------------------------------------------------

% This statement is truth even physically such big data amounts we have to solve on bigger cluster like cesnet.metacenter. \todo{mention data amount before and after processing pipeline}
% After we decided which data parts are useful we used linux tools and Julia language to \todo{reference Julia in appendix technology description and maybe even lazyjson library} extract what we need from original analysis results \todo{reference what we used in bash - if necessary (maybe I can add to attachment bash script with trasformation like that if needed), and reference pruner code in attachements, we should have appendix description of attachments}


% "behavior
%     "processes, "processtree  - list of processes related to malware run with details (api name, arguments...)
%     "summary
%         "files
%         "read_files
%         "write_files
%         "delete_files
%         "keys
%         "read_keys
%         "resolved_apis    
%     "enhanced - detail sequence of events (library loading, api calls with parameters...)


% \todo{more about them we say in chapter on modelling, or maybe here give example of code and signature detection and data part (and all parts) and to appendix we can add more, with reference to the repository}

% Describe parts of json report
% JSON report parts \todo{describe that json report is quite comprehensive and contain even earlier mentioned outputs} \todo{to appendix we should add some example of report.json}
% - size vary a lot, could be from 10MB to GBs
% lack of docs - https://github.com/cuckoosandbox/cuckoo/issues/2458

% "statistics - time statistics for particular part of malware analysis
% "info - sandbox details (machine, category, used modul...)
%     "version"
%     "started"
%     "ended"
%     "duration"
%     "id"
%     "category"
%     "custom"
%     "machine
%     "package"
%     "timeout"
% "CAPE - extraxted payload
% "behavior
%     "processes
%     "processtree
%     "summary
%     "enhanced
% "debug - debug log of sandbox
% "deduplicated_shots - screenshots
% "network
%     "domains
%     "tcp
%     "udp
%     "dns
%     "pcap_sha256"
%     "sorted_pcap_sha256"
% "static - static analysis of files
% "strings - extracted strings (static analysis technique)
% "suricata - network detection Suricata tool log
% "target - sample details
% "malfamily_tag"
% "signatures - list of signatures and their data
% "malscore"
% "ttps

% paragraph about each and resoning on if we can use it or not, and what kind of analysis can be based on particular part (I think we enumerated almost all parts of original log)


% Summary of the data set - How many samples, size...
% Also we can try to specify the requirements for our model (quite big amount of data - all the reports), we are not able to process whole outputs, reference hmill capacities on previous experiments (for example in Julia language)


% \todo{Final result of data collection - no internet samples (maybe mention at the end of previous chapter), I did collect some, but did not use them in further parts because priority was not to have everything}

% Their analysis is in future work same as data from static analysis (Virus total). These data are still part of our data set and was big part of our job so far. So the subject of our research is sandox output.

% Previous connection
% - Follow up statements about data in cybersecurity, follow previous chapter with choosing relevant parts of logs
% Way through this chapter, we do not use internet access data, because we did not have it at right time, no internet data are sufficient for our further experimentation
% Next connection
% - Chosen data will be used for further experiments


% reference some source that is talking about data in cyber security, resp. on theory part

% Data processing
% extracting desired parts
% Is there something else in processing?
% Pruning jsons in Julia...

% reference that we did use similar parts as predecessors (Pevny, Mandlik, Stiborek)

% Detail descriptions of candidates, for example describe signatures (just describe what they do and sort them to categories according to what they are doing) and give example and at once slightly say why the signatures could be interesting (based on behavior like this we can validate model, such that it is using the proper part of report, but we can see whatever else which looks like malicious)


% Next chapter - Due to the data quality we are not able to use some of them

% Get several reasonings for some parts of analysis, what we want and we do not, also we can compare it to Stiborek and other works (for example Mandlik had quite straight-forward dataset and we know that it worked), we can really investigate the whole output and present ideas. 


% At the end we can have more variants, but at the end we did examine two and that should not be a problem