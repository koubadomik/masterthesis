

% \todo{describe part one goal - We involve more theory and prior work research, in following chapters we discuss our case.}
% In the first part of this thesis we focus the comprehensive theory which is needed to absorb in order to interpret results. Not everything is disassembled in detail we go only there where we find something useful for our thesis. This is really based on experience so if the reader is interested only in results used formalism and notation in theory part are important only.

\chapter{Malware analysis} \label{chap:analysis}
Particular goal of this thesis is to create dataset of dynamic malware analyses. In this chapter we define basic notions of malware, PE file, malware analysis. We describe sandbox which we use for analysis and its output. We also address some cyber security challenges and refer to prior arts.


\section{Data cybersecurity challenges}
We address challenges which we found from our point of view and then we refer to the ones listed in \cite{Amit2019}. Authors of that paper also list available datasets for specific kinds of machine learning task in the cybersecurity.

All challenges are based on the complexity of cyber security domain. There are only few industries that are so flexible, dynamic and fast. There are terabytes of data every second in the cybersecurity - cloud, IoT, general network traffic\dots. The supervised machine learning is still the most reliable so we want these data to be labelled. But the detection itself has to be fast because the most significant is ability to detect malware variants (based on similar attributes) and of course zero-day attacks (unseen). Repeated observation might not be possible because modern malware is flexible which could be seen on malware analysis evasion techniques \cite{Afianian2018}. Huge concern is also bias in the data itself caused by multiple things - size, noise, sensibility to small deviations. For instance, if we run several malware samples in sandbox which has access to the internet and malware is able to access its public ip address the bias might be caused by the geographical location of edge router. This is something which could ruin our dataset. Another kind of bias is encryption as mention in the thesis introduction.

Regarding the lack of labeled and certainty in ground truth we can address several problems. If the labelling process is done by human, it become slow and subjective. So the better approach is to develop some heuristic like black lists, white lists or more complex rules, models. That knowledge is little bit more systematic but still not shared which leads us to consensus techniques. This approach is based on combining knowledge from several sources. The goal should be to generalize our detection, but it has another pitfall which are \emph{Advanced Persistent Threats} that are often disposable and unique attack. However, the quality of labelling determines real performance of our future model and its reliable evaluation. Finally, it is sometimes too complex to automate the labelling process, some hope can give us the involvement of unsupervised techniques like anomaly detection or active learning in combination with semisupervised learning.

If we can collect the dataset we should care about its quality. Imbalanced datasets are not speciality of the cybersecurity but it is often presented. The population of specific attacks is not distibuted equally and even the ratio between benign and malicious vary in time. So the balance of our dataset is strongly dependent on the time of data collection. The problem of concept drift is also related to the development over time. It simply addresses the trend of decreasing performance of machine learning models due to the difference of training data in the past and current data. This could be solved by new model or even by ability of adapting existing models in new situations.

% Last remarkable not is many times analyzed statistical assumption
% My
% Data quality, bias, antisandbox detection... where to find samples? (we should definitely mention motivation why we are collecting our own data), public data (this is quite risky to publish in general), everything is fast (zero days), Are those anomalies or malicious?, Imbalanced data sets, encryption everywhere - what to trust..., cryptocurrencies, iot, cloud





\todo{add some motivation example or latest results... - known malware attacks..}

Philosophy could be walking around risk management, probability of risk and resulting damage... Maybe more examples of situations where we know how much it cost (Cambridge analytica, ransomware...)
Maybe something about truth and its protection in the world of lies and fake news
Confidentiality, integrity and availability

Use found books or post-hoc go through some articles and formulate the motivation part...

\section{JSON notation} \label{sec:json_notation}
(define json notation in short paragraph)




\section{Malware}
Generally types of attacks and just the intro, to settle the malware into wider context
Definition of cleanware and malware
Types, Families
https://en.wikipedia.org/wiki/Malware
Find in books!
https://www.sciencedirect.com/science/article/pii/S1084804519303868 - good overview and taxonomy of malware

\section{Portable executable files}
Malware is defined widely and is not limited to specific kind of file format. In our research we decided to investigate only Portable Executable (PE) files. It is because we want to create dataset of malware running on windows machines with no extra extension. 

In general we can find various filetypes. In list below we list some examples with basic principle how particular type is used for system intrusion or harm. From the definition of malicious code we can derive that whichever filetype could by used but some are more usual than another (easier to use).
\begin{enumerate}
  \item Portable executable
  \item Portable Document Format
  \item Microsoft office formats
  \item Compressed
\end{enumerate}

https://en.wikipedia.org/wiki/Portable_Executable
https://docs.microsoft.com/en-us/windows/win32/debug/pe-format
https://github.com/corkami/pics/blob/master/binary/pe101/README.md

\section{Malware analysis}
introduction

https://en.wikipedia.org/wiki/Malware_analysis
Find in books!

\subsection{Dynamic}
https://publications.sba-research.org/publications/malware_survey.pdf
https://link.springer.com/article/10.1007/s11416-007-0074-9

mention especially parts which gives more information about the run (mutexes, files, api calls,.. - to be able to reference from data chapter)

- Summary of potential sorces of metadata
○ Abuse.ch - https://bazaar.abuse.ch/api/#api_key
○ VirusTotal - https://developers.virustotal.com/v3.0/reference#file-info
○ Metadefender - https://onlinehelp.opswat.com/mdcloud/3.1_Retrieving_scan_reports_using_a_data_hash.html
- Interesting
○ https://app.any.run/
○ https://virusscan.jotti.org/
○ https://virscan.org/
○ https://mzrst.com/
○ https://github.com/maliceio/malice
https://www.hybrid-analysis.com/

\subsection{Static}
○ Retdec - static analyser
§ Not so well documented..
§ I am studying the output, there is decompiled code and there some metada
§ I will use as it is out of box - decompiled code and some metadata
○ Manalyze
§ Another metadata like clamav signatures and something else


\section{Sandboxing}
existing solutions and results...
find basics in books

api hooking, dumping import reconstruction debugging static parsing - https://www.youtube.com/watch?v=qEwBGGgWgOM

to appendix we can add also web interface of cuckoo


\section{Produced data}
mention signatures
usual format which are produced by sandbox and what we can find there
Reference even docs - no problem, not only books and papers
Conclusion should be that those data are complicated and their structure also keep some information (order, structure...), that is why we want to focus on structured data and especially json.
size...

\section{Prior}
works about malware analysis
works that collected data for machine learning purposes
Mandlik, Stiborek, everybody who used cuckoo or other sandbox data (reference for what and their results)

file:///C:/Users/domia/Downloads/Imad-Saiida-IJCNIS-V11-N6-1.pdf
https://web.archive.org/web/20160418151823/http://www.ijarcsse.com/docs/papers/Volume_3/4_April2013/V3I4-0371.pdf
https://reader.elsevier.com/reader/sd/pii/S1383762120301442?token=81F1AB06FF0FE40D1B7745234269280FCF2CB0979140E84DB35D6E04A2C622FE6EDA2DE4DA0630E1D73044E3D84A722F&originRegion=eu-west-1&originCreation=20210401090943
https://iopscience.iop.org/article/10.1088/1742-6596/1140/1/012042/pdf
file:///C:/Users/domia/Downloads/JCIT4024PPL.pdf
https://dl.acm.org/doi/abs/10.1145/2046614.2046618?casa_token=MXpfHiylCZcAAAAA:szRMPWfKXTl4wxP2-h32eknCg5dzM2t7RxGjywiJDksmT5FqcUY7pPrIBZchv26HUe3Lwubu5Hru

file:///C:/Users/domia/Downloads/088851962.pdf


%%------------------------------------------

% Previous connection
% - Nothing before
% Way through this chapter
% - Malware definition and types
% - Malware analysis
% - Challenges
% - Data - input, output...
% - prior
% Next connection
% - We are interested in modeling the data using modern approaches, we know that the data are often structured somehow and that is what we will solve

% - GOALS
%   - Run several instances of CapeV2 sandbox and solve their orchestration for this experiment
%   - Capture behavior of selected malware samples in CapeV2 sandbox and store results
% - Theory part - types, conditions, bias, Malware types, signatures....
% - Sandboxing
% - Previous experiments
% - Our goal in this part
% - Data collection for ML purposes in general


% https://www.groundai.com/project/machine-learning-in-cyber-security-problems-challenges-and-data-sets/1

% https://www.readitquik.com/articles/security-2/cybersecurity-challenges-that-need-to-be-on-your-radar-right-now/