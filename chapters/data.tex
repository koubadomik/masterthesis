\chapter{Data structure, features and states}
So far we know that sandbox output can be quite rich. There re even such experiments that used machine learning algorithms on all the produced data but we would like to use some subset. In this chapter we describe our reasoning on choosing feature vector and hidden states.

The input for us to this chapter are collected malware analysis results from previous part. The expected output is reasoning on what we can use as features for \emph{hmill} model. This decision should be based on the data we have and even on experience from prior work (reference Mandlik, Pevny, Stiborek and maybe even others and really compare my decisions with them)

The outputs of the analysis are quite comprehensive, but we have only some setup. We did collect much more than we can use. Regarding this fact we were not able to use data with internet connection because its collection is quite complicated and at the time we wanted examine it we did not have it. Their analysis is in future work same as data from static analysis (Virus total). These data are still part of our data set and was big part of our job so far. So the subject of our research is sandox output.

Among goals of this thesis is to investigate different parts of sandbox output responsible for some kinds of behavior. This is why we aim at the parts of log where we can see behavior of target malware sample. Those are:
\begin{enumerate}
  \item \emph{pcap reports} - network traffic report
  \item \emph{memory dump} - dump of RAM memory
  \item \emph{bingraph} - \todo{based on the paper}
  \item \emph{behavioral logs} - in raw form (usually bson)
  \item \emph{files} - dropped files
  \item \emph{CAPE} - \todo{investigate configurations and https://www.youtube.com/watch?v=qEwBGGgWgOM} extracted payload
  \item \emph{procdump}
  \item \emph{reports} - reports generated by sandbox reporting moduls (especially \emph{report.json} contains comprehensive amount of behavioral information)
  \item \emph{shots} - screenshots of machine screen during sample run
\end{enumerate}
\todo{checkout some web interface example, if there is something else, and even configuration files}


paragraph about each and resoning on if we can use it or not)
https://ieeexplore.ieee.org/document/6461015 - bingraph


JSON report parts \todo{describe that json report is quite comprehensive and contain even earlier mentioned outputs} \todo{to appendix we should add some example of report.json}
- size vary a lot, could be from 10MB to GBs
lack of docs - https://github.com/cuckoosandbox/cuckoo/issues/2458

"statistics - time statistics for particular part of malware analysis
"CAPE - extraxted payload
"info - sandbox details (machine, category, used modul...)
    "version"
    "started"
    "ended"
    "duration"
    "id"
    "category"
    "custom"
    "machine
    "package"
    "timeout"
"behavior
    "processes
    "processtree
    "summary
    "enhanced
"debug - debug log of sandbox
"deduplicated_shots - screenshots
"network
    "domains
    "tcp
    "udp
    "dns
    "pcap_sha256"
    "sorted_pcap_sha256"
"static - static analysis of files
"strings - extracted strings (static analysis technique)
"suricata - network detection Suricata tool log
"target - sample details
"malfamily_tag" - 
"signatures - list of signatures and their data
"malscore"
"ttps




Reasoning on choice of apropriate input
- here they used json reports - file:///C:/Users/domia/Downloads/088851962.pdf, file:///C:/Users/domia/Downloads/TSP_CMC_40145.pdf, https://core.ac.uk/download/pdf/237431148.pdf, https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8262998

Complete description of the output of the sandbox is in appenix \todo{reference}.



Final result of data collection - no internet samples (maybe mention at the end of previous chapter), I did collect some, but did not use them in further parts because priority was not to have everything

Technology - Julia
  - describe why and basic features and advantages and cons


How many samples, size...
Summarize what we know from previous sections and go to the most concetrated information about run of program - we should end at the things which are in summary part of json log, but we can have more variants
we can even mention virustotal reports here

Get several reasonings for some parts of analysis, what we want and we do not, also we can compare it to Stiborek and other works (for example Mandlik had quite straight-forward dataset and we know that it worked), we can really investigate the whole output and present ideas. Also we can try to specify the requirements for our model (quite big amount of data and we have to demonstrate on device we have)


Detail descriptions of candidates, for example describe signatures (just describe what they do and sort them to categories according to what they are doing) and give example and at once slightly say why the signatures could be interesting (based on behavior like this we can validate model, such that it is using the proper part of report, but we can see whatever else which looks like malicious)

At the end we can have more variants, but at the end we did examine two and that should not be a problem

Data processing
extracting desired parts
Is there something else in processing?
Pruning jsons in Julia...


reference that we did use similar parts as predecessors (Pevny, Mandlik, Stiborek)

Basic statistics for various parts and variants
  - signature histogram (balanced) - histogram.csv
  - ...
  - a lot of Emotet (maybe should be on another place)
  - - Balanced dataset - in term of accuracy metric performance
  - Bias - - Bias in practical data like this - security data, what are the influences (as an example could be ip addresses...)


After data investigation and processing we are moving to modelling. This statement is truth even physically such big data amounts we have to solve on bigger cluster like cesnet.metacenter.

Previous connection
- Follow up statements about data in cybersecurity, follow previous chapter with choosing relevant parts of logs
Way through this chapter, we do not use internet access data, because we did not have it at right time, no internet data are sufficient for our further experimentation
Next connection
- Chosen data will be used for further experiments


reference some source that is talking about data in cyber security, resp. on theory part
  


Explaining:
  Reasoning:
  - compare
    code - original sample
    code - only summary part

    (nice-to-have, I do not have it, I can show just example of original sample, I do not think this is important), locally I can check it by hand

    code - explanation
  - discuss explanation
  - report 
      explanations, example of code, avarage size of explanation compared to average size of samples
      parameters - used explainer, confidence...

  - compare code and data part of original signature with the original report (if we can find there something) and then with explanation
  - compare it in case of original report and in case of 



Using:

DIRECTLY in output
	- API calls - are in in summary part
		○ "injection_rwx" 28251
		○ "antidebug_setunhandledexceptionfilter" 18223
		○ "removes_zoneid_ads" 11070
		○ "deletes_self" 10805
		○ "stealth_timeout" 8253
		○ "enumerates_running_processes" 6324
		○ "injection_runpe"  5542
  - Files - are in summary part
		○ "copies_self" 7137
	- Commands - are in summary part
		○ "uses_windows_utilities" 6987

NOT DIRECTLY in output
	- Processes - not directly in summary part
		○ "dropper"  6045
	- Time - not directly in summary part
		○ "antisandbox_sleep" 15810
	- AuthSign - not directly in summary part
		○ "invalid_authenticode_signature" 14346
	- Entrophy - not directly in summary part
		○ "packer_entropy" 8815
	- Combinations - 
    "stealth_network" 26430
