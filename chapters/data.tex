\chapter{Data structure, features and states} \label{chap:data}

% \todo{this chapter could be absorbed into next chapter if it is too short...}
% \todo{do not forget to add goals to each chapter and go through the trash below each chapter!!}

The outputs of previous chapter are dynamic malware analysed samples. There are even such experiments that used machine learning algorithms on all the produced data but this is very performance demanding because the output may have 15~\emph{MB} but even gigabytes. That is why we want to choose only subset which we find containing the most information about the run and behavior. 

The goal of this thesis is to use \emph{hmill} model (copmrehensively desribed in \ref{chap:hmill}) which is able to work with graph-structured data and especially with json files. This fact we would like to use.

Our approach is to create simple binary classifier and then scale up to multiclass or even multilabel if it is possible regarding performance and time we have. In this chapter we describe our reasoning on choosing features and hidden states for our \emph{hmill} classifier. The input are collected results and the expected output is set of features and states (maybe more than one possibility). This decision should be based on the data we have and even on experience from prior work we reference to.


\section{Dataset}
We have some of results which were mentioned in \ref{chap:infrastructure}. At the time we start following reasoning we have proper amount of the data without internet access because the setup is straight-forward and easier. The setup with the internet connection and its collected data will be investigated in the future work as its collection continues. 

The data in such domain are very biased (\ref{chap:class}). Sometimes we can see that malware is not able to be run under the conditions in virtual machine or it is trying to use some \emph{.NET} library and if not found it kills itself. The fact that we do not have internet connection can make this bias stronger so it has to be counted on in making the decision on what to use to train the model. We definitely do not want to investigate network activities even if sometimes it contains something (malware attempts).

The dataset we have consists of $80000$ different samples. Complete data have \texttildelow$2,5$~\emph{TB} where the analysis result is compressed.

The documentation of the output is quite weak but there is some (\url{https://cuckoo.readthedocs.io/en/latest/usage/results/}) and we also investigated outputs themselves. The output of general \emph{CAPEv2} sandbox analysis is described in table \ref{tab:sandbox-out}.

\begin{table}[h]
    \centering
    \caption{CAPEv2 Sandbox output (all possibilities)}
    \begin{tabular}{p{2cm}p{6cm}p{6cm}} 
        \toprule
        \textbf{Output} &
        \textbf{Meaning} &
        \textbf{In our output} \\
        \midrule
        pcap report & network traffic record (packet sequences) & Presented in output but not significant regarding the fact that during run was not internet access \\
        \midrule
        memory dump & dump of RAM (its analysis results could be also presented)& Our version of sandbox do not support it \\
        \midrule
        bingraph & mechanism that discovers metamorphic malware \cite{Kwon2012}& Presented\\
        \midrule
        behavioral log & raw logs of api calls and other (usually in bson) & Presented \\
        \midrule
        dropped files & all dropped files are unchanged in separate directory & Presented \\
        \midrule
        CAPE, procdump & Other extraxted payload in separate directory, extracted by various techniques \cite{Cape} & Presented \\
        \midrule
        reports & Sandbox allows us using several reporting and processing modules, their results are in separate directory  & Several of them presented but the most comprehensive and important is \emph{report.json} \\
        \midrule
        screenshots & All taken during analysis  & Presented \\
        \bottomrule
    \end{tabular}
    \label{tab:sandbox-out}
\end{table}

Not all the outputs are presented in each sample. \emph{CAPEv2} presents results using web interface for example here \url{https://capesandbox.com/}~(after authentication).

There are various experiments involving machine learning approaches with analysis result input. Based on the fact that a lot of them use \emph{report.json} as main input \cite{Darshan2016, Dinh2019a, Kim2020, Sethi2019}, we would like to investigate this report firstly. This report includes everything what the sandbox is able to provide. It also covers the majority of the storage on the disk so included information is very comprehensive (see \ref{tab:report}). As we are not very sure which parts are suitable for us this report is quite convenient and compared to mentioned authors we have model which accepts json documents.

% \todo{Summarize what we know from previous sections \todo{especially from analysis part, where we should summarize what usual program is doing in the computer and what we can observe (and what we can get from cuckoo monitor)} and go to the most concetrated information about run of program - we should end at the things which are in summary part of json log, but we can have more variants}

\section{Report}
\emph{JSON} notation is described in \ref{sec:json_notation}. The report has usually tens of megabytes but sometimes even gigabytes. It is quite easy to compress, we can have even 10 times less storage because it contains a lot of redundancies (sequencies of api calls\dots). 

The documentation of each part of the report is again quite poor but a lot of attributes are self-descriptive. Complete schema is in \ref{tab:report}. In attachments we can see example of real log (\ref{app:attach})

\begin{table}[h]
    \centering
    \caption{Parts of \emph{report.json}}
    \begin{tabular}{p{2cm}p{12cm}} 
        \toprule
        \textbf{Entry} &
        \textbf{Meaning} \\
        \midrule
        statistics & time statistics for particular part of malware analysis \\
        \midrule
        info & sandbox details (machine, category, used modul, timeout...) \\
        \midrule
        debug & sandbox debug log \\
        \midrule
        target &  info about examined sample\\
        \midrule
        CAPE & extracted payload info \\
        \midrule
        behavior & processes, mutexes, commands and other attributes as enhanced log but even summary view \\
        \midrule
        deduplicated shots & screenshot summary \\
        \midrule
        network & network traffic report (domains, tcp, udp\dots) \\
        \midrule
        static analysis & results per file \\
        \midrule
        strings & extracted strings \\
        \midrule
        suricata &  output of suricata network detection tool (\url{https://suricata.readthedocs.io/en/latest/quickstart.html})\\
        \midrule
        malfamily tag &  malware family detection result\\
        \midrule
        malscore &  malware sample metric\\
        \midrule
        signatures &  list of signatures which were detected by sandbox with their attributes \\
        \bottomrule
    \end{tabular}
    \label{tab:report}
\end{table}

\section{Features and states for classification}
Our goal is to train classifier so we need to find appropriate $\mathcal{X}, \mathcal{Y}$ (\emph{features} and \emph{states} as defined in \ref{chap:classification}). Following our statements we find them in \emph{report.json}. More than one possibilites are stated and based on further conditions we are going to train models on some of input data combination/s.

\subsection{States}
We know that our samples are malware based on the source of original files as we mentioned in previous chapter \ref{chap:infrastructure}. So it does not make sense to try \emph{malware X cleanware} classification. The classification classes has to be related to the malwaware itself, its attributes and behavioral signs.

From the \emph{report.json} we extracted three candidates \emph{malware family}, \emph{signatures}, \emph{malscore}. All those attributes we can see as dependent variables where independent are some behavioral features or combination of behavioral and static features. 

Assigning \emph{malware family} is very complex task \cite{Gennari2011}, we often involve the behavior of the sample and its similarity to other samples. Usual process involves some kind of decomposition of this task to deterministic detection of specific behavior and classfying according to their combination. Potential model could attempt to generalize family assignment process (like in \cite{Rieck2008}) and point out features which could be used in more complex way than usual deterministic ones. Straght-forward thinking about this task is that it is more a clustering task - we need to find families and use them to categorize old and new samples \cite{Pitolli2017}. Specific malware families are mentioned in chapter \ref{chap:analysis}

\emph{Malware score} has multiple definitions in a lot of papers (\cite{Walker2019, Kumar2014})and that is a crucial problem of these metrics. Of course in case of CAPEv2 sandbox we can investigate its implementation but the future classifier will be dependent on it. On the other hand potential classifier could assign score based on more complex decisions and we could observe where it is against original human-defined assignment. But this is quite risky because even the original malscore assignement is complex decision consisting from a serie of steps. Examining it like blackbox should not be the first thinkg which we want to use. We rather want to use its causes.

\emph{Signatures} most often tells us what sandbox observed, e.g. \ special kind of behavior, static features\dots We can see them as local detectors which are checking particular feature in the malware analysis result. Potential model could again generalize their assignment or even investigate other malicious signs that are often connected with some signatures - find new signatures or existing behavior correlating with original signature assignment.

\subsection{Features}
Following the assumption that our state candidates are related to the behavior of malware sample we choose some subset of the original \emph{report.json} which is related to that. We omit static features, state candidates and everything not related to behavior. Two things remain - network and behavior part. In our dataset we do not have relevant network traffic due to the data collection details mentioned above. We take into consideration only behavior part of the original report. Its structure can be seen in \ref{tab:behavioral} and its example in attachment (\ref{app:attach}).

\begin{table}[h]
    \centering
    \caption{Parts of \emph{report.json} behavior}
    \begin{tabular}{p{2cm}p{12cm}} 
        \toprule
        \textbf{Entry} &
        \textbf{Meaning} \\
        \midrule
        processes & list of processes related to malware execution with details (api names, arguments\dots) \\
        \midrule
        process tree & structure of process execution\\
        \midrule
        summary & list of occured files, registry keys, mutexes, executed commands, api calls \\
        \midrule
        enhanced & comprehensive log of events during malware execution including parameters and timestamps and other\\
        \bottomrule
    \end{tabular}
    \label{tab:behavioral}
\end{table}

As feature vector could be used the whole section or its segments. We have to be aware of a potential bias like timestamps which are in enhanced and processes parts. We would have to involve some preprocessing in case of using some of them as features.

Technologies used for data pruning and other parts of preprocessing are listed in \ref{app:technologies}. Code is in attachment (\ref{app:attach}).

The goal of this chapter was to describe potential states and features. We know that to train the model we concentrate on specific parts of \emph{report.json}. We are moving to modeling itself.



% Lastly thrown out
% We would like to base our decision on the fact that in \ref{chap:analysis} we stated that crucial observations during the program run are \emph{processes, files, mutexes, registries, commands, api calls}.

% NICE to have
% We can try to create some histogram using the data from virus total (families or something like that...)
% \todo{checkout some web interface example, if there is something else, and even configuration files}
% \todo{add sections of report from virus total and its features}
% https://developers.virustotal.com/v3.0/reference#files
% \todo{add some image}

%%----------------------------------------------------------------------------------------------

% This statement is truth even physically such big data amounts we have to solve on bigger cluster like cesnet.metacenter. \todo{mention data amount before and after processing pipeline}
% After we decided which data parts are useful we used linux tools and Julia language to \todo{reference Julia in appendix technology description and maybe even lazyjson library} extract what we need from original analysis results \todo{reference what we used in bash - if necessary (maybe I can add to attachment bash script with trasformation like that if needed), and reference pruner code in attachements, we should have appendix description of attachments}


% "behavior
%     "processes, "processtree  - list of processes related to malware run with details (api name, arguments...)
%     "summary
%         "files
%         "read_files
%         "write_files
%         "delete_files
%         "keys
%         "read_keys
%         "resolved_apis    
%     "enhanced - detail sequence of events (library loading, api calls with parameters...)


% \todo{more about them we say in chapter on modelling, or maybe here give example of code and signature detection and data part (and all parts) and to appendix we can add more, with reference to the repository}

% Describe parts of json report
% JSON report parts \todo{describe that json report is quite comprehensive and contain even earlier mentioned outputs} \todo{to appendix we should add some example of report.json}
% - size vary a lot, could be from 10MB to GBs
% lack of docs - https://github.com/cuckoosandbox/cuckoo/issues/2458

% "statistics - time statistics for particular part of malware analysis
% "info - sandbox details (machine, category, used modul...)
%     "version"
%     "started"
%     "ended"
%     "duration"
%     "id"
%     "category"
%     "custom"
%     "machine
%     "package"
%     "timeout"
% "CAPE - extraxted payload
% "behavior
%     "processes
%     "processtree
%     "summary
%     "enhanced
% "debug - debug log of sandbox
% "deduplicated_shots - screenshots
% "network
%     "domains
%     "tcp
%     "udp
%     "dns
%     "pcap_sha256"
%     "sorted_pcap_sha256"
% "static - static analysis of files
% "strings - extracted strings (static analysis technique)
% "suricata - network detection Suricata tool log
% "target - sample details
% "malfamily_tag"
% "signatures - list of signatures and their data
% "malscore"
% "ttps

% paragraph about each and resoning on if we can use it or not, and what kind of analysis can be based on particular part (I think we enumerated almost all parts of original log)


% Summary of the data set - How many samples, size...
% Also we can try to specify the requirements for our model (quite big amount of data - all the reports), we are not able to process whole outputs, reference hmill capacities on previous experiments (for example in Julia language)


% \todo{Final result of data collection - no internet samples (maybe mention at the end of previous chapter), I did collect some, but did not use them in further parts because priority was not to have everything}

% Their analysis is in future work same as data from static analysis (Virus total). These data are still part of our data set and was big part of our job so far. So the subject of our research is sandox output.

% Previous connection
% - Follow up statements about data in cybersecurity, follow previous chapter with choosing relevant parts of logs
% Way through this chapter, we do not use internet access data, because we did not have it at right time, no internet data are sufficient for our further experimentation
% Next connection
% - Chosen data will be used for further experiments


% reference some source that is talking about data in cyber security, resp. on theory part


% Data processing
% extracting desired parts
% Is there something else in processing?
% Pruning jsons in Julia...

% reference that we did use similar parts as predecessors (Pevny, Mandlik, Stiborek)

% Detail descriptions of candidates, for example describe signatures (just describe what they do and sort them to categories according to what they are doing) and give example and at once slightly say why the signatures could be interesting (based on behavior like this we can validate model, such that it is using the proper part of report, but we can see whatever else which looks like malicious)


% Next chapter - Due to the data quality we are not able to use some of them

% Get several reasonings for some parts of analysis, what we want and we do not, also we can compare it to Stiborek and other works (for example Mandlik had quite straight-forward dataset and we know that it worked), we can really investigate the whole output and present ideas. 


% At the end we can have more variants, but at the end we did examine two and that should not be a problem