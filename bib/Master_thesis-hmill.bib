Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@techreport{Frank2003,
author = {Frank, Eibe and Xu, Xin},
title = {{Applying propositional learning algorithms to multi-instance data}},
year = {2003}
}
@misc{Zaheer2018,
archivePrefix = {arXiv},
arxivId = {cs.LG/1703.06114},
author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan and Smola, Alexander},
eprint = {1703.06114},
primaryClass = {cs.LG},
title = {{Deep Sets}},
year = {2018}
}
@inproceedings{Pevny2016a,
abstract = {Modelling network traffic is gaining importance to counter modern security threats of ever increasing sophistication. It is though surprisingly difficult and costly to construct reliable classifiers on top of telemetry data due to the variety and complexity of signals that no human can manage to interpret in full. Obtaining training data with sufficiently large and variable body of labels can thus be seen as a prohibitive problem. The goal of this work is to detect infected computers by observing their HTTP(S) traffic collected from network sensors, which are typically proxy servers or network firewalls, while relying on only minimal human input in the model training phase. We propose a discriminative model that makes decisions based on a computer's all traffic observed during a predefined time window (5 minutes in our case). The model is trained on traffic samples collected over equally-sized time windows for a large number of computers, where the only labels needed are (human) verdicts about the computer as a whole (presumed infected vs. presumed clean). As part of training, the model itself learns discriminative patterns in traffic targeted to individual servers and constructs the final high-level classifier on top of them. We show the classifier to perform with very high precision, and demonstrate that the learned traffic patterns can be interpreted as Indicators of Compromise. We implement the discriminative model as a neural network with special structure reflecting two stacked multi instance problems. The main advantages of the proposed configuration include not only improved accuracy and ability to learn from gross labels, but also automatic learning of server types (together with their detectors) that are typically visited by infected computers.},
address = {New York, NY, USA},
author = {Pevny, Tomas and Somol, Petr},
booktitle = {Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security},
doi = {10.1145/2996758.2996761},
isbn = {9781450345736},
keywords = {big data,learning indicators of compromise,malware detection,neural network,user modeling},
pages = {83--91},
publisher = {Association for Computing Machinery},
series = {AISec '16},
title = {{Discriminative Models for Multi-Instance Problems with Tree Structure}},
url = {https://doi.org/10.1145/2996758.2996761},
year = {2016}
}
@inproceedings{Maron1998,
author = {Maron, Oded and Lozano-P{\'{e}}rez, Tom{\'{a}}s},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Jordan, M and Kearns, M and Solla, S},
publisher = {MIT Press},
title = {{A Framework for Multiple-Instance Learning}},
url = {https://proceedings.neurips.cc/paper/1997/file/82965d4ed8150294d4330ace00821d77-Paper.pdf},
volume = {10},
year = {1998}
}
@misc{PevnyKovarik2019a,
archivePrefix = {arXiv},
arxivId = {cs.LG/1906.00764},
author = {Pevny, Tomas and Kovarik, Vojtech},
eprint = {1906.00764},
primaryClass = {cs.LG},
title = {{Approximation capability of neural networks on spaces of probability measures and tree-structured domains}},
year = {2019}
}
@mastersthesis{Mandlik2020,
author = {Mandlik, Simon and Pevny, Tomas},
publisher = {Czech Technical University in Prague},
title = {{Mapping the Internet — Modelling Entity Interactions in Complex Heterogeneous Networks}},
year = {2020}
}
@inproceedings{Andrews2003,
author = {Andrews, Stuart and Tsochantaridis, Ioannis and Hofmann, Thomas},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Becker, S and Thrun, S and Obermayer, K},
publisher = {MIT Press},
title = {{Support Vector Machines for Multiple-Instance Learning}},
url = {https://proceedings.neurips.cc/paper/2002/file/3e6260b81898beacda3d16db379ed329-Paper.pdf},
volume = {15},
year = {2003}
}
@article{Stiborek2018,
abstract = {This work addresses classification of unknown binaries executed in sandbox by modeling their interaction with system resources (files, mutexes, registry keys and communication with servers over the network) and error messages provided by the operating system, using vocabulary-based method from the multiple instance learning paradigm. It introduces similarities suitable for individual resource types that combined with an approximative clustering method efficiently group the system resources and define features directly from data. This approach effectively removes randomization often employed by malware authors and projects samples into low-dimensional feature space suitable for common classifiers. An extensive comparison to the state of the art on a large corpus of binaries demonstrates that the proposed solution achieves superior results using only a fraction of training samples. Moreover, it makes use of a source of information different than most of the prior art, which increases the diversity of tools detecting the malware, hence making detection evasion more difficult.},
author = {Stiborek, Jan and Pevn{\'{y}}, Tom{\'{a}}s̆ and Reh{\'{a}}k, Martin},
doi = {https://doi.org/10.1016/j.eswa.2017.10.036},
issn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {Classification,Dynamic analysis,Malware,Multiple instance learning,Random forest,Sandboxing},
pages = {346--357},
title = {{Multiple instance learning for malware classification}},
url = {https://www.sciencedirect.com/science/article/pii/S0957417417307170},
volume = {93},
year = {2018}
}
@misc{Amores2013,
abstract = {Multiple Instance Learning (MIL) has become an important topic in the pattern recognition community, and many solutions to this problem have been proposed until now. Despite this fact, there is a lack of comparative studies that shed light into the characteristics and behavior of the different methods. In this work we provide such an analysis focused on the classification task (i.e., leaving out other learning tasks such as regression). In order to perform our study, we implemented fourteen methods grouped into three different families. We analyze the performance of the approaches across a variety of well-known databases, and we also study their behavior in synthetic scenarios in order to highlight their characteristics. As a result of this analysis, we conclude that methods that extract global bag-level information show a clearly superior performance in general. In this sense, the analysis permits us to understand why some types of methods are more successful than others, and it permits us to establish guidelines in the design of new MIL methods. {\textcopyright} 2013 Elsevier B.V.},
author = {Amores, Jaume},
booktitle = {Artificial Intelligence},
doi = {10.1016/j.artint.2013.06.003},
issn = {00043702},
keywords = {Bag-of-Words,Codebook,Multi-instance learning},
title = {{Multiple instance classification: Review, taxonomy and comparative study}},
year = {2013}
}
@inproceedings{Bunescu2007,
abstract = {We present a new approach to multiple instance learning (MIL) that is particularly effective when the positive bags are sparse (i.e. contain few positive instances). Unlike other SVM-based MIL methods, our approach more directly enforces the desired constraint that at least one of the instances in a positive bag is positive. Using both artificial and real-world data, we experimentally demonstrate that our approach achieves greater accuracy than state-of-the-art MIL methods when positive bags are sparse, and performs competitively when they are not. In particular, our approach is the best performing method for image region classification.},
address = {New York, NY, USA},
author = {Bunescu, Razvan C and Mooney, Raymond J},
booktitle = {Proceedings of the 24th International Conference on Machine Learning},
doi = {10.1145/1273496.1273510},
isbn = {9781595937933},
pages = {105--112},
publisher = {Association for Computing Machinery},
series = {ICML '07},
title = {{Multiple Instance Learning for Sparse Positive Bags}},
url = {https://doi.org/10.1145/1273496.1273510},
year = {2007}
}
@techreport{Xu2003,
author = {Xu, Xin},
title = {{Statistical learning in multiple instance problems}},
year = {2003}
}
@article{Dietterich1997,
address = {GBR},
author = {Dietterich, Thomas G and Lathrop, Richard H and Lozano-P{\'{e}}rez, Tom{\'{a}}s},
doi = {10.1016/S0004-3702(96)00034-3},
issn = {0004-3702},
journal = {Artif. Intell.},
keywords = {drug design,machine learning,structure-activity relationships},
number = {1–2},
pages = {31--71},
publisher = {Elsevier Science Publishers Ltd.},
title = {{Solving the Multiple Instance Problem with Axis-Parallel Rectangles}},
url = {https://doi.org/10.1016/S0004-3702(96)00034-3},
volume = {89},
year = {1997}
}
@inproceedings{Pevny2017,
abstract = {Many objects in the real world are difficult to describe by means of a single numerical vector of a fixed length, whereas describing them by means of a set of vectors is more natural. Therefore, Multiple instance learning (MIL) techniques have been constantly gaining in importance throughout the last years. MIL formalism assumes that each object (sample) is represented by a set (bag) of feature vectors (instances) of fixed length, where knowledge about objects (e.g., class label) is available on bag level but not necessarily on instance level. Many standard tools including supervised classifiers have been already adapted to MIL setting since the problem got formalized in the late nineties. In this work we propose a neural network (NN) based formalism that intuitively bridges the gap between MIL problem definition and the vast existing knowledge-base of standard models and classifiers. We show that the proposed NN formalism is effectively optimizable by a back-propagation algorithm and can reveal unknown patterns inside bags. Comparison to 14 types of classifiers from the prior art on a set of 20 publicly available benchmark datasets confirms the advantages and accuracy of the proposed solution.},
address = {Cham},
author = {Pevn{\'{y}}, Tom{\'{a}}{\v{s}} and Somol, Petr},
booktitle = {Advances in Neural Networks - ISNN 2017},
editor = {Cong, Fengyu and Leung, Andrew and Wei, Qinglai},
isbn = {978-3-319-59072-1},
pages = {135--142},
publisher = {Springer International Publishing},
title = {{Using Neural Network Formalism to Solve Multiple-Instance Problems}},
year = {2017}
}
@inproceedings{Keeler1991,
author = {Keeler, James and Rumelhart, David and Leow, Wee},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Lippmann, R P and Moody, J and Touretzky, D},
publisher = {Morgan-Kaufmann},
title = {{Integrated Segmentation and Recognition of Hand-Printed Numerals}},
url = {https://proceedings.neurips.cc/paper/1990/file/e46de7e1bcaaced9a54f1e9d0d2f800d-Paper.pdf},
volume = {3},
year = {1991}
}
